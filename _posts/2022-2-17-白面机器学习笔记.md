---
layout:     post
title:      "白面机器学习笔记"
subtitle:   ""
date:       2022-02-17 22:00:00
updatedate:
author:     "Jpy"
header-img: "img/post-bg-2015.jpg"
no-catalog: False
onTop: false
latex: false
# 生活，工作，笔记（个人理解消化心得），文档（方便后续查阅的资料整理），项目，其他
tags:
    - 笔记
---

# 特征工程

## 特征归一化

目的：1. 消除数据特征之间的量纲影响，使不同指标之间具有可比性。2. 帮助更快梯度下降找到最优解。

常用方法：1. Min-Max scaling 2. Z-Score Normalization

决策树不需要归一化

## 类别型特征

1. 序号编码(Ordinal Encoding)

成绩->(高：3，中：2，低：1)

2. 独热编码(One-hot Encoding)

如有四类，第一类为(1,0,0,0)，第二类为(0,1,0,0) ... 可以使用稀疏向量形式

3. 二进制编码(Binary Encoding)

先进行序号编码，再将序号转为二进制表示

## 高维组合特征的处理

目的：为了提高复杂关系的拟合能力，在特征工程中经常把一阶离散特征两两组合，构成高阶组合特征。

将两特征的各取值一一组合形成新特征，当某一特征值太多时，比如某一特征为用户ID时，可以考虑用低维向量k表示？这样特征取值便从$$m\times n$$减少为$$m\times k + n \times k $$，相当于走了一个全连接降维。

## 组合特征

简单两两组合特征取值往往很多组合是无意义的，如何有效地找到组合特征呢？可以选用决策树的方式。

将一条决策树的路径（西瓜重量>10斤 并且 西瓜甜）看作是一个组合特征，有**多少条**组合特征则对应了一个多少维的向量。当新数据输入时，将符合的组合特征的对应位置标为1，否则为0.

## 文本表示模型

词袋模型：将一篇文章表示成一个长向量，忽略单词顺序。

如句子`John likes to watch movies. Mary likes movies too`.

```
[
    "John",
    "likes",
    "to",
    "watch",
    "movies",
    "also",
    "football",
    "games",
    "Mary",
    "too"
]
```

向量每一维代表频次，`[1, 2, 1, 1, 2, 0, 0, 0, 1, 1]`。

常用TF-IDF模型计算权重  
$$
TF-IDF(t,d)=TF(t,d) \times IDF(t)
$$

$$
IDF(t) = \log \frac{文章总数}{包含单词t的文章总数+1}
$$

很多时候，我们还需要关注短语，因此将短语当作一维也可以放入，这种做法叫`N-gram`模型。

## Word2Vec

word2Vec是一种浅层的神经网络模型，有两种网络结构，CBOW(Continues Bag of Words)和Skip-gram。

![Word2Vec的两种网络结构](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220121223750540.png)

1. CBOW相当于从上下文的词（滑动窗口），经过独热编码（有N个词则用N维向量表示）作为输入层。目标是获取当前t时刻的词的向量表示。
2. 在映射层中维度为K，则采用$$N\times K$$矩阵乘法得到，同时将各输入的结果求SUM。
3. 输出层也是一个N维的向量，使用$$N\times K$$矩阵与映射层输出矩阵相乘得到输出，利用Softmax函数计算每个单词的概率。

$$
softmax: P(y=w_n|x)= \frac{e^{x_n}}{\sum_{k=1}^{N} e^{x_k}}
$$

word2vec与LDA的区别：LDA是利用文档中单词共现关系对单词按主题聚类，word2vec是对上下文-单词矩阵进行学习。LDA是主题模型，是一种基于概率图模型的生成模型，其似然函数可以写成若干条件概率连乘的形式。word2vec是词嵌入模型，词嵌入模型一般是神经网络的形式，似然函数定义在网络输出之上，需要通过学习网络的权重以得到单词的稠密向量表示。

## 图像数据不足时的处理方法

1. 基于模型，主要采用降低过拟合风险的措施。简化模型，L1L2正则，集成学习，Dropout。
2. 基于数据
   1. 数据扩充。对图像变换、添加噪点、改变颜色、改变亮度、清晰度等。
   2. 除了直接在图像空间进行变换，还可以先对图像进行特征提取，然后在图像的特征空间内进行变换，例如SMOTE。
   3. 生成模型合成新样本，生成式对抗网络模型。
3. 迁移学习。借助在大规模数据集上预训练好的通用模型，在针对目标任务的小数据集上进行微调。

# 模型评估

## 评估指标的局限性

分类指标

|              | Predict True | Predict False |
| ------------ | ------------ | ------------- |
| Actual True  | TP           | FN            |
| Actual False | FP           | TN            |

1. Accuracy 准确率 $$\frac{TP+TN}{TP+FN+FP+TN}$$

非均衡数据集带来问题

2. Precision 精确率 $$\frac{TP}{TP+FP}$$与 Recall 召回率 $$\frac {TP}{TP+FN}$$

$$
F1=\frac{2\times precision \times recall}{precision + recall}
$$

P-R曲线的横轴是召回率，纵轴是精确率。与ROC曲线一致，从左到右，是模型阈值降低的过程，每个P-R曲线上的点代表了某一模型阈值取值时Precision与Recall的值。

回归指标

1. RMSE

$$
RMSE=\sqrt{\frac{\sum_{i=1}^{n}(y_i-\hat {y_i})^2}{n}}
$$

问题：如果存在少量outlier时，即使outliers很少，RMSE指标也很差。

解决方法

1. 认为有噪点，则在预处理时处理掉

2. 认为不是噪点，则需要优化模型，考虑这些数据

3. 更换鲁棒性更好的模型，如MAPE。
   $$
   MAPE=\sum_{i=1}^{n}|\frac {y_i-\hat{y_i}}{y_i}|\times \frac {100}{n}
   $$

   $$
   sMAPE=\sum_{i=1}^{n}\frac {|y_i-\hat{y_i}|}{(|\hat {y_i}|+|y_i|)/2}\times \frac {100}{n}
   $$


## ROC

横坐标为假阳性率$$FPR=FP/(FP+TN)$$,代表假样本有多少被预测为了正样本。

纵坐标为真阳性率$$TPR=TP/(TP+FN)$$,其实就是recall。

一般二分模型都是概率模型，而ROC图像中不同的点对应的是不同阈值下的分类模型。左下角，即FPR=TPR=0的点为设置阈值为正无穷（针对分类为正类而言），而右上角，FPR=TPR=1的点为设置阈值为0的点。

什么是AUC？AUC（area under curve）指ROC曲线下的面积，面积越大，则分类器越可能把真正的正样本排在前面，分类性能越好。

ROC曲线与P-R曲线的区别：

1. ROC曲线形状基本保持不变，而P-R曲线形状一般会发生较剧烈的变化。可以应对实际场景中正负样本数量很不平衡的情况。

## 余弦距离的应用

$$
cos(A,B)=\frac{A \cdot B}{\| A \|_2 \|B\|_2}
$$

在一些场景中为什么不使用欧氏距离而使用余弦相似度？如一对文本相似度的长度差距很大，但内容相近时，余弦值较小，欧氏距离大。

具体情况具体分析，不是一定余弦相似度就一定最好

比如word2Vec中，所有向量都已归一化，说明向量在单位圆上，则根据定理
$$
\|A-B\|_2 = \sqrt {2(1-\cos(A,B))}
$$
该式子可以左边平方拆开得证，所以在此情况下，左边的欧氏距离与右边余弦距离有单调关系，使用两种距离都是相同的效果。

**余弦距离不是一个严格定义的距离**

(1) d(p,q)>=0 (2) d(p,q) = d(q,p) (3) d(p,r) <= d(p,q) +d(q,r)

余弦距离满足（1）（2），但不满足（3），举例A（1，0）B（1，1）C（0，1）

## A/B测试的陷阱

为什么在充分离线评估之后，还要进行在线A/B测试？

1. 离线评估无法完全消除模型过拟合的影响
2. 离线评估无法完全还原线上的工程环境，如延迟、数据丢失、标签数据缺失等情况
3. 线上系统的某些商业指标（点击率、留存时长）等在离线评估中无法计算

## 模型评估的方法

主要验证方法及优缺点

1. Holdout检验： 将数据简单划分为一定比例的训练集与一定比例的验证集。

缺点：训练出的模型与数据集划分有很大关系，因此引入交叉验证

2. 交叉验证：
   1. k-fold交叉验证
   2. 留一验证：每次留下1个样本作为验证集，其余所有样本作为训练集。
3. 自助法 Bootstrap：对总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集。没被采样到的样本作为验证集。

对于一个样本来说，n次均未被抽中的概率为$$(1-\frac {1}{n})^n$$，根据定理$$\lim_{n \to \infty} (1+\frac {1}{n})^n = e$$

![image-20220122221335684](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220122221335684.png)
$$
=\frac{1}{e}\approx0.368
$$

## 超参数优化

明确：1. 目标函数 2. 搜索范围 3. 算法的其他参数，如搜索步长

网格搜索：查找搜索范围的所有点。在较大的搜索范围以及较小的步长的情况下，很有可能找到全局最优值，但十分消耗计算资源和时间。

随即搜索：与网格搜索类似，但只在测试上界和下界之间随机选取样本点。

贝叶斯优化算法：首先根据先验分布，假设一个搜集函数；然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。  但一旦找到一个局部最优值，会在该区域不断采样，容易陷入局部最优解。

## 过拟合与欠拟合

过拟合：模型过于复杂，把噪声数据的特征也学习到模型中，导致模型泛化能力下降。

降低过拟合和欠拟合的方法

* 降低过拟合的方法：
  * 获取更多的训练数据，是最有效的，直接获取数据困难，可以数据增强。
  * 降低模型复杂度
  * 正则化，比如将权值大小加入损失函数，避免权值过大带来过拟合。
  * 集成学习
* 降低欠拟合的方法：
  * 添加新特征
  * 增加模型复杂度
  * 减小正则化系数

# 经典算法

 ## 支持向量机

## 逻辑回归

将逻辑回归公式进行整理，可以得到$$log\frac{p}{1-p}=\theta^Tx$$,逻辑回归可以看作是对于$$y=1|x$$这一事件的对数几率的线性回归。

逻辑回归与线性回归异同

异

1. 本质上，逻辑回归处理分类问题，线性回归处理回归问题
2. 在逻辑回归中，我们认为y是因变量，而非$$\frac{p}{1-p}$$，即逻辑回归中的因变量为离散的，线性回归中是连续的。在自变量$$x$$与超参数$$\theta$$确定的情况下，逻辑回归可以看作广义线性模型在因变量y服从二元分布时的一个特殊情况。

同

1. 二者都使用了极大似然估计来对训练样本进行建模
2. 二者在求解超参数的过程中，都可以使用梯度下降

## 决策树

ID3： 最大信息增益 
$$
H(D)=\sum _{k=1}^{K} p_i \log_2 {\frac{1}{p_i}}
$$
C4.5：最大信息增益比

计算特征A对数据集D的信息增益比为**特征A对D的信息增益/数据集D关于A的取值熵**

相当于对分支做了一次惩罚，希望不要过多分支，优化ID3

处理连续值的例子：[(26条消息) C4.5连续值处理方法 & 常见连续值处理方法_shushi6969的博客-CSDN博客_连续值处理](https://blog.csdn.net/shushi6969/article/details/120227875)

思路为将连续值特征排序，后计算每两个取值之间的平均值作为候选分裂点，计算各分裂点能获得的信息增益比，选取信息增益比最大的点作为真实分裂点。

CART：GINI系数
$$
Gini(D)=1-\sum_{k=1}^{n} p_k^2
$$

|                  | ID3  | C4.5 | CART |
| ---------------- | ---- | ---- | ---- |
| 能否处理连续变量 | 否   | 能   | 能   |
| 任务类型         | 分类 | 分类 | 回归 |
| 能否多叉树       | 能   | 能   | 否   |
| 特征能否重复使用 | 否   | 否   | 能   |

**剪枝**

---

预剪枝：

1. 根据深度
2. 根据节点的样本数，小于一定值则剪枝
3. 计算分裂对测试集的准确率提升，小于阈值则剪枝

后剪枝：

如CART树采用的后剪枝方法：

1. 从完整决策树$$T_0$$开始，生成一个子树序列，$${T_0,T_1,T_2,...,T_n}$$，其中$$T_{i+1}$$由$$T_i$$生成，$$T_n$$为根节点。

   对每个节点计算
   $$
   \alpha = \frac{R(t)-R(T_t)}{|L(T_t)|-1}
   $$
   $$R(t)$$为以内部节点t为单节点树的损失函数值，$$R(T_t)$$为以t为根节点的子树的损失函数值，$$|L(T_t)|$$为以t为根节点的子树的叶子节点个数。$$\alpha$$可以表示剪枝后整体损失函数增大的程度，$$\alpha$$越小，代表决策树损失函数增大越少，代表剪枝效果越好。所以遍历每个节点，计算各节点$$\alpha$$值，将$$\alpha$$值最小的结点剪枝，将当前剪枝后的子树加入子树序列。

   循环，直到只剩下完整决策树的根节点。

2. 在子树序列中，根据真实误差选择最佳决策树。（找独立剪枝数据集，找出误差最小的子树；使用当前数据集，k-fold交叉验证，k-1份训练，1份用来选择最优子树，重复N次，选择N棵较优子树中的最优）

# 优化算法

## 有监督的损失函数有哪些？有什么特点(没懂)

分类问题

* 0-1损失函数：非凸非光滑，算法很难针对该函数直接优化

$$
L_{0-1}(f,y)=1_{fy \leq0}
$$

* Hinge函数：在fy=1处不可导，不能用梯度下降法优化

$$
L_{hinge}(f,y)=max \{ 0,1-fy\}
$$

* Logistic损失函数：光滑，可用梯度下降；但对所有样本点都有惩罚，对异常值敏感

$$
\begin{cases} L_{logistic}(f,y)=log_{2}(1+exp(-fy)) & label=[-1,1] \\
L_{logistic}(f,y)=-fy+\log \left(1+e^{f}\right) & label=[0,1]
\end{cases} 
$$

第二个式子可与交叉熵公式互推。两个式子的推导可见[Which loss function is correct for logistic regression?](https://stats.stackexchange.com/questions/250937/which-loss-function-is-correct-for-logistic-regression)

* 交叉熵

$$
L_{cross entropy}(f,y)=-log_{2} (\frac{1+fy}{2})
$$

![image-20220125165906882](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220125165906882.png)

回归问题

* MSE 平方损失函数：对异常值惩罚很大
* MAE 绝对损失函数：相比MSE对异常值更鲁棒一些；但在f=y处无法求导
* Huber损失函数：相当于结合了MSE与MAE的优点

$$
L_{\text {Huber }}(f, y)= \begin{cases}(f-y)^{2}, & |f-y| \leqslant \delta \\ 2 \delta|f-y|-\delta^{2}, & |f-y|>\delta\end{cases}
$$

## 机器学习中的优化问题

凸优化问题

什么是凸函数？函数L是凸函数当且仅当对定义域中的任意两点x,y和任意实数$$\lambda \in [0,1]$$总有
$$
L(\lambda x+(1-\lambda) y) \leqslant \lambda L(x)+(1-\lambda) L(y)
$$
即

![image-20220126013114815](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220126013114815.png)

可以通过计算目标函数的二阶Hessian矩阵来验证凸性，观察矩阵是否满足半正定的性质，若满足则为凸函数。

## 经典优化算法

直接法与迭代法

#### 直接法

直接$$\nabla L(\theta^*)=0$$，得出$$\theta^*$$。

直接法有两个前提条件：

1. $$L(\cdot)$$是凸函数
2. 该式子有闭式解

#### 迭代法

假设当前对最优解的估计值为$$\theta_t$$，希望求解问题：
$$
\delta_t= \mathop{\arg\min}\limits_{\delta} L(\theta_t + \delta)
$$
很好理解，想引入一个变化量$$\delta$$，使损失函数最小，找到该步最优变化量为$$\delta _t$$

* 一阶法（梯度下降法）

一阶法对$$L(\theta_t+\delta)$$一阶泰勒展开
$$
L\left(\theta_{t+1}\right)=L\left(\theta_{t}+\delta\right) \approx L\left(\theta_{t}\right)+L^{\prime}\left(\theta_{t}\right) \delta
$$
由于近似值仅在$$\delta$$较小时才比较准确，因此一般加上一个$$L_2$$正则加以限制
$$
L(\theta_t)+L^{\prime}(\theta_t)\delta+\frac{1}{2\alpha}\|\delta\|_{2}^{2}
$$
对上式关于$$\delta$$求导，使得导数为0，可以得到$$\delta_t=-\alpha L^{\prime}(\theta_t)$$

所以，$$\theta_{t+1}=\theta_t-\alpha L^{\prime}(\theta_t)$$

复习一下泰勒公式：
$$
f(x)=\frac{f\left(x_{0}\right)}{0 !}+\frac{f^{\prime}\left(x_{0}\right)}{1 !}\left(x-x_{0}\right)+\frac{f^{\prime \prime}\left(x_{0}\right)}{2 !}\left(x-x_{0}\right)^{2}+\ldots+\frac{f^{(n)}\left(x_{0}\right)}{n !}\left(x-x_{0}\right)^{n}+R_{n}(x)
$$

* 二阶法（牛顿法 2nd order approximation）

二阶法对$$L(\theta_t+\delta)$$二阶泰勒展开
$$
L\left(\theta_{n}\right)=L\left(\theta_{n-1}+\Delta \theta\right) \approx L\left(\theta_{n-1}\right)+L^{\prime}\left(\theta_{n-1}\right) \Delta \theta+\frac{L^{\prime \prime}\left(\theta_{n-1}\right) \Delta \theta^{2}}{2}
$$
将该式对$$\delta$$求导，使得导数为0，得$$\Delta \theta=-\frac{L_{n-1}^{\prime}}{L_{n-1}^{\prime \prime}}$$

拓展到高维，$$1/ L_{n-1}^{\prime \prime}$$可以表示为Hession矩阵$$H$$

所以，
$$
\theta_{t+1}=\theta_t- \frac{L_{n-1}^{\prime}}{L_{n-1}^{\prime \prime}}=\theta_t - H^{-1} L_{n-1}^{\prime}
$$
二阶法优缺点：收敛速度远快于一阶法；但在高维情况下，Hessian矩阵求逆的计算复杂度很大，而且当目标函数非凸时，二阶法可能会收敛到鞍点。

## 梯度验证

如何验证梯度计算正确

对$$\theta$$的某个维度，有
$$
\frac{\partial L(\theta)}{\partial \theta_{i}}=\lim _{h \rightarrow 0} \frac{L\left(\theta+h e_{i}\right)-L\left(\theta-h e_{i}\right)}{2 h}
$$
当$$h$$值较小时，两边近似相等。我们将右侧分子中的两个式子看作是对h单变量的函数，泰勒展开后计算，可得
$$
\frac{L\left(\theta+h e_{i}\right)-L\left(\theta-h e_{i}\right)}{2 h}=\frac{\partial L(\theta)}{\partial \theta_{i}}+\frac{1}{12}\left(\tilde{L}^{(3)}\left(p_{i}\right)+\tilde{L}^{(3)}\left(q_{i}\right)\right) h^{2}
$$
即
$$
\left|\frac{L\left(\theta+h e_{i}\right)-L\left(\theta-h e_{i}\right)}{2 h}-\frac{\partial L(\theta)}{\partial \theta_{i}}\right| \approx M h^{2}
$$
可得在$$h$$很小时，$$h$$每减小为原先的1/10，近似误差（即上式左侧，近似梯度减去真实梯度）减小为原先的1/100。

根据该性质，我们可以先验证
$$
\left|\frac{L\left(\theta+h e_{i}\right)-L\left(\theta-h e_{i}\right)}{2 h}-\frac{\partial L(\theta)}{\partial \theta_{i}}\right| \leqslant h
$$
因为$$Mh$$必小于1，所以上式是一个比较宽泛的条件。

若上式不满足，则可能是因为1. M值太大了，导致$$Mh$$值比较大，上式不成立了 2. 梯度计算错了

再将h降为原先的1/10，观察对应的近似误差是否降为原先的1/100，若遵循，则采用更小的h进一步验证梯度；若不遵循，则梯度计算有误。

## 随机梯度下降法

经典的梯度下降法，在每次迭代时需要使用所有的训练数据。

因为经典的梯度下降法采用所有训练数据的平均损失来近似目标函数，即
$$
L(\theta)=\frac{1}{M} \sum_{i=1}^{M} L\left(f\left(x_{i}, \theta\right), y_{i}\right) \\
\theta_{t+1}=\theta_{t}-\alpha \nabla L\left(\theta_{t}\right)
$$
因此需要很大的计算量，在实际应用中基本不可行。

所以为了解决这个问题，随机梯度下降法（Stochastic Gradient Descent, SGD）用单个训练样本的损失来近似平均损失，即
$$
\begin{aligned}
&L\left(\theta ; x_{i}, y_{i}\right)=L\left(f\left(x_{i}, \theta\right), y_{i}\right), \\
&\nabla L\left(\theta ; x_{i}, y_{i}\right)=\nabla L\left(f\left(x_{i}, \theta\right), y_{i}\right)
\end{aligned}
$$
为了降低随机梯度的**方差**，使训练更稳定，在实际使用中会使用小批量梯度下降法（Mini-Batch Gradient Descent）。
$$
\begin{aligned}
&L(\theta)=\frac{1}{m} \sum_{j=1}^{m} L\left(f\left(x_{i_{j}}, \theta\right), y_{i_{j}}\right), \\
&\nabla L(\theta)=\frac{1}{m} \sum_{j=1}^{m} \nabla L\left(f\left(x_{i_{j}}, \theta\right), y_{i_{j}}\right)
\end{aligned}
$$

1. 如何选取m？一般选2的幂次方，可以充分利用矩阵运算操作，如32，64，128
2. 如何挑选m个训练数据？读入数据时shuffle，避免数据的特定顺序给算法收敛带来影响
3. 如何选取学习率$$\alpha$$？通常采用衰减学习速率的方案。

# 前向神经网络

# 循环神经网络

## 循环神经网络和卷积神经网络

卷积神经网络通常处理定长向量，处理变长的字符串或单词串时也是通过滑动窗口+池化的方式转成定长向量处理。二循环神经网络可以很好处理文本数据变长并且有序的输入序列。

## RNN中的梯度消失

$$
\frac{\partial n e t_{t}}{\partial n e t_{1}}=\frac{\partial n e t_{t}}{\partial n e t_{t-1}} \cdot \frac{\partial n e t_{t-1}}{\partial n e t_{t-2}} \cdots \frac{\partial n e t_{2}}{\partial n e t_{1}}
$$

循环神经网络的梯度可以表示为连乘形式

这里书上引入了雅可比矩阵（P_239），但没能看懂书中公式的各个维度。可以参考[gradient-notes.pdf (stanford.edu)](https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf)

主要思路是各项累乘会造成梯度指数性上升或下降。梯度消失时，只有靠近输出层的网络得到了有效训练；而梯度爆炸时，靠近输入层的网络的梯度变动极大，导致训练不稳定。

## 梯度消失与梯度爆炸的原因与解决

可能原因：梯度消失：1. 深层网络 2. 不合适的损失函数，如选择了sigmoid激活函数，其导数最大为0.25，极易累乘导致梯度消失。 梯度爆炸：1. 深层网络 2. 权值初始化太大

解决方法：

梯度消失：1. 深度残差网络，引入残差学习的方式，使我们能学习到更深层的网络表示 2. LSTM及各种变种门控循环单元，弥补了梯度消失所带来的损失 3. batch norm

梯度爆炸：1. 梯度裁剪，当梯度大于某个给定值时，对梯度进行等比收缩 

能有效预防梯度爆炸，如果梯度长度超过$$\theta$$，就把长度投影回$$\theta$$
$$
\mathbf{g} \leftarrow \min \left(1, \frac{\theta}{\|\mathbf{g}\|}\right) \mathbf{g}
$$

2. 通过正则化限制w不过大 3. batch norm

## RNN中的激活函数

循环神经网络中能否使用Relu作为激活函数？

可以，但需要权重矩阵W取值在单位矩阵附近才会有较好效果。

因为使用Relu激活，假设所有的神经元都处于激活状态，则循环神经网络的每一层梯度均为W。因为在激活这一步的梯度均为1，矩阵形式是单位矩阵。所以在连乘计算中$$\frac{\partial net_t}{\partial net_1} = W^n$$，只有W是单位矩阵才不会出现梯度爆炸或梯度消失。

## LSTM

引入遗忘门、输入门、输出门。输入门控制当前信息多少加入到记忆单元C，遗忘门控制需要保留多少记忆单元中的信息，输出门控制当前的输出有多大程度上取决于当前记忆单元。

![image-20220126220443667](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220126220443667.png)
$$
\begin{gathered}
i_{t}=\sigma\left(W_{i} X_{t}+U_{i} h_{t-1}+b_{i}\right), \\
f_{t}=\sigma\left(W_{f} X_{t}+U_{f} h_{t-1}+b_{f}\right), \\
o_{t}=\sigma\left(W_{o} X_{t}+U_{o} h_{t-1}+b_{o}\right), \\
\tilde{c}_{t}=\operatorname{Tanh}\left(W_{c} X_{t}+U_{c} h_{t-1}\right), \\
c_{t}=f_{t} \odot c_{t-1}+i_{t} \odot \tilde{c}_{t}, \\
h_{t}=o_{t} \odot \operatorname{Tanh}\left(c_{t}\right) .
\end{gathered}
$$
关注倒数第二个公式，更新记忆单元的公式。也就是说，在当前输入信息不重要时，遗忘门参数$$f_t$$近似为1，输入门参数$$i_t$$近似为0，而当前信息重要时则相反。

## LSTM中的激活函数

三个门的模块一般都选择sigmoid作为激活函数。在LSTM中，不管sigmoid还是tanh，都是饱和的，也就是说在输入达到一定值的情况下，输出就不会发生明显变化了。符合门控的物理定义。

## Seq2Seq

有编码器与解码器，各由一个循环神经网络构成。

在编码中，根据经典RNN模式读入数据，获取embedding；在解码器中，解码器读入编码器的最终状态，生成第一个输出，再将第一个输出作为后一步的输入，循环，直到输出终止状态。

![seq2seq](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220126231925327.png)

seq2seq在解码中，若每次生成的候选输出，我们只选一个最优解，则称为贪心法。如果，我们每次都选择b（beam size）个较佳选择，则称为集束搜索。贪心法为b取一的特殊的集束法。一般b大一些效果会好一些，但计算量也相应增大，一般取8至12。

![image-20220126232856501](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220126232856501.png)

## 注意力机制

在seq2seq中，我们有一个明显的缺点，还是很难处理长序列的输入，最前面的输入信息丢失非常严重。

注意力机制就是为了解决这个问题，引入了语境向量，描述编码层中每个隐状态对当前节点的输出预测的重要程度。

![image-20220126234448459](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220126234448459.png)
$$
\begin{gathered}
s_{i}=f\left(s_{i-1}, y_{i-1}, c_{i}\right) \\
c_{i}=\sum_{j=1}^{T} \alpha_{i j} h_{j} \\
\alpha_{i j}=\frac{\exp \left(e_{i j}\right)}{\sum_{k=1}^{T} \exp \left(e_{i k}\right)} \\
e_{i j}=a\left(s_{i-1}, h_{j}\right)
\end{gathered}
$$
$$s_i$$是解码层的隐状态，$$c_i$$是语境向量，通过注意力权重参数$$\alpha_{ij}$$与编码层的隐状态$$h_j$$计算得到，对每个解码层的隐状态，$$c_i$$的值都是重新计算的。(i下标对应的是解码层状态，j下标对应的是编码层状态)

注意力权重$$\alpha_{ij}$$是通过对齐值$$e_{ij}$$得到的，$$e_{ij}$$是通过一个神经网络$$a$$，输入解码层上一隐状态与某一编码层隐状态比较得到。

简单来说，就是想告诉当前计算的节点，前面编码层中的哪些隐状态与我们现在的语境相似，我们应该给他们更高的权重。

在公式中，我们可以发现在计算$$c_i$$时，我们使用的是$$h_j$$，但$$h_j$$是一个顺序编码的过程，即$$h_j$$只能包含$$h_0 - h_j$$的信息，后文的内容被丢失了。所以，一般可以在建模时再次将源语言逆序输入，称为双向循环神经网络，效果会有较大提升。

# 强化学习

## 强化学习基础

基础概念：environment, Agent, State, Action, Reward

强化学习的核心人物是，学习一个从状态空间S到动作空间A的映射，最大化累积收益。

### Value Iteration

Bellman Equation
$$
V_{*}(s)=\max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid s, a\right)\left[r+\gamma V_{*}\left(s^{\prime}\right)\right]
$$
初始化各state value为0。每一次迭代，对每个state的每一个可能的action都作一次计算，根据bellman equation更新该state的value值。

经过多次迭代后，我们可以根据每个state的value得到一条最优路径。

### Policy Iteration

分为两步，evaluation与improvement

初始化各state的action为随机action。每一次迭代，首先evaluation，根据当前给的action更新一次各state的value；再进行improvement，更新策略，由当前state走向周围value最大的state_next。直到policy不再改变，结束迭代。

## 视频游戏里的强化学习

Q-learning page 264

## 策略梯度

## 探索与利用



# 集成学习

## 集成学习的种类
