---
layout:     post
title:      "Dive Into Deep Learning"
subtitle:   "动手学深度学习"
date:       2021-10-20 18:00:00
author:     "Jpy"
header-img: "img/deeplearning.png"
# 生活，工作，笔记（个人理解消化心得），文档（方便后续查阅的资料整理），其他
tags:
    - 笔记
---

# 前言

深入学习深度学习是李沐博士出版的书，最近偶然发现出了直播教程，正好最近的项目需要用到神经网络，所以跟着学习了一番。

# Week1

数据中的类别值或离散值，可以将`NaN`视为一个类别

```python
inputs = pandas.get_dummies(inputs,dummy_na = True)
```

Tensor的reshape是不会更换地址的

```python
a = torch.arange(12)
b = a.reshape((3,4))
b[:] = 2
a # 这里打印出来的a也是被改为元素均为2
```

神经网络的正向反向的复杂度其实是差不多的。

**如何存梯度以及读取梯度**

```python
x.requires_grad_(True)
x.grad.zero_() # 在下一次计算时要把梯度清零
y = 关于x的计算
y.backward()
x.grad # 访问梯度
```

# Week2

线性回归问题，线性模型可以看作是单层的神经网络

优化时，深度学习比较常用小批量随机梯度下降。因为在整个训练集上算梯度花费太高。因此可以随机采样一些样本计算近似损失。

线性回归notebook：https://zh-v2.d2l.ai/chapter_linear-networks/linear-regression-scratch.html

Softmax回归

回归和分类有较大的不同。分类问题通常有多个输出，输出i是预测第i类的置信度。

sofemax可以把正负值转化为概率，即预测为某一类的概率，相当于**多分类**。

# Week3

## 感知机

感觉是经典的神经网络结构？

output = wx+b

**多层感知机**：可以弥补单层感知机的缺陷，如感知机不能处理XOR分类问题。

## 为什么需要非线性激活函数？

因为没有激活函数，多层的感知机还是线性的变换，其实依然相当于一个单层的线性模型。

常用激活函数：Sigmoid ReLU Tanh

ReLU(x) = max(x,0)，为什么很多时候用relu，因为很简单，相比其他激活函数不用用到指数运算。

![](https://cdn.jsdelivr.net/gh/Jia-py/blog_picture/21_4/Snipaste_2021-04-18_13-34-18.jpg)

**一层隐藏层理论上可以拟合任何函数，为什么不是去增加隐藏层的神经元而是去增加层数呢？**因为，单层很多神经元的网络结构不容易训练。而多层较少神经元的网络结构比较容易训练。

## 模型选择

训练误差：模型在**训练数据**上的误差

泛化误差：模型在**新数据**上的误差**（我们关心的）**

验证数据集：一个用来评估模型好坏的数据集，可以调参。

测试数据集：只用一次的数据集，不能用来调参。

K-则交叉验证：在没有足够多的数据时使用（常态）。将数据分割为K块，使用第i块作为验证数据集，其余的作为训练数据集。

## 过拟合与欠拟合

在简单数据集上应用复杂（高容量）模型，容易过拟合。

在复杂数据集上应用简单（低容量）模型，容易欠拟合。

模型的容量指的是模型拟合函数的能力。

![](https://cdn.jsdelivr.net/gh/Jia-py/blog_picture/21_4/Snipaste_2021-04-18_14-53-44.jpg)

## QA

1. 超参数的设计？经验；比较推荐随机方法选超参数
2. 数据不均衡时如何选择训练数据集、验证集？验证集尽量保证是均衡分布的

# week4

## 权重衰退

通过限制w权重始终小于一个值(硬性限制，每一个w都小于某一个值)

![](https://cdn.jsdelivr.net/gh/Jia-py/blog_picture/21_4/Snipaste_2021-04-24_10-54-23.jpg)

与加入正则项的作用很相似(柔性的限制)

![](https://cdn.jsdelivr.net/gh/Jia-py/blog_picture/21_4/Snipaste_2021-04-24_10-54-55.jpg)

*为什么叫权重衰退*：每次在更新参数时，都先给（1-λn）w作一次缩小。λ是我们用来控制模型复杂度的超参数。

## QA

1. 为什么参数小就代表复杂度小呢？其实这里不是说参数小就复杂度小，只是在模型选取参数时，给它限制了参数选择的范围，使得模型的空间相对不作限制小了很多。
2. 一般权重衰退的值设置多少为好呢？一般取0.001

## Dropout

dropout有人说相当于一个正则。

对x加入噪音后，希望其期望不变，依然是x。

丢弃法对每个元素进行如下的扰动，将一些输出项随机置0来控制模型复杂度，常用于多层感知机的隐藏层输出上。

![](https://cdn.jsdelivr.net/gh/Jia-py/blog_picture/21_4/Snipaste_2021-04-24_11-50-17.jpg)

那么在这时，期望E = P*0 + (1-P)\*(x/(1-P)) = x

![](https://cdn.jsdelivr.net/gh/Jia-py/blog_picture/21_4/Snipaste_2021-04-24_11-53-26.jpg)

# 数值稳定性

梯度爆炸与梯度消失，因为链式法则会有很多次乘法。

梯度爆炸的问题：

* 梯度超出值域（一般用的16位浮点数）
* 对学习率敏感

梯度消失的问题：

* 梯度值变为0，训练无进展
* 使训练只对顶层训练较好，对底部层没有效果

## 如何让训练更稳定

**合理的权重初始化和激活函数的选取**

将乘法作加法，如ResNet,LSTM

Xavier初始化方法，得知该层的输入输出维度，可以确定初始化参数，相对保证权重的期望为0，方差固定。

要完成这个目标，激活函数如
$$
\begin{equation}\sigma(x)=\alpha x+\beta\end{equation}
$$
也需要满足α=1，β=0

可以看到常用的激活函数是符合这个规律的
$$
\begin{equation}\tanh (x)=0+x-\frac{x^{3}}{3}+O\left(x^{5}\right)\end{equation}
$$

$$
\begin{equation}\operatorname{relu}(x)=0+x \quad$ for $x \geq 0\end{equation}
$$

sigmoid 需要经过一点变换
$$
\begin{equation}\operatorname{sigmoid}(x)=\frac{1}{2}+\frac{x}{4}-\frac{x^{3}}{48}+O\left(x^{5}\right)\end{equation}
$$

$$
\begin{equation}4 \times \operatorname{sigmoid}(x)-2\end{equation}
$$

# PyTorch基础

pytorch中任何一个层，一个模型都是nn.Module的子类

取权重状态可以用`net.state_dict()`，偏移可以用`net.bias`

# 卷积层

pytorch中卷积层的简单调用

```python
conv2d = nn.Conv2d(1,1,kernel_size=(1,2),bias=False) # 参数为输入通道数、输出通道数、卷积核大小，偏移
input = X.reshape((1,1,6,8))# 形状为通道数，batchsize，长，宽
output = Y.reshape((1,1,6,7))
```

## 卷积层里的填充Padding和步幅Stride

填充 （针对输入的填充）

可以使得卷积之后的输出，维度更大一些，可以使用更大的卷积核，更深的网络。

![image-20211020140530712](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20211020140530712.png)

如图所示，蓝框所标注的为原始的输入，经过填充一圈0后，使得卷积后输出比原始输入维度还大。

一般会取`padding_height = kernel_height - 1, padding_width = kernel_width - 1`，如此输出的维度会与原始输入维度一致。

步幅

可以控制卷积核每次移动的步幅，如高度3宽度2的步幅。

**可以说，填充是为了尽量延长卷积的过程，而步幅是尽量加快卷积的过程。**

```python
# pytorch代码实现
# 通过padding参数控制填充
# 通过stride参数控制步幅
nn.Conv2d(1,1,kernel_size=3,padding=(0,1), stride=(2,3))
```

## 卷积层里的多输入多输出通道

每个通道都有一个卷积核，结果是所有通道卷积结果的和

![](https://github.com/Jia-py/blog_picture/blob/master/img/image-20211020142510632.png?raw=true)

这样得到的输出通道是单通道

如何获得多输出通道呢？只需要设置n组kernel即可，即设置多个输出单输出通道的卷积核组，这样就可以输出多个输出通道了。

为什么要多输入多输出通道呢？因为每个不同的通道可以识别不同的模式，比如一个通道识别猫耳朵，一个通道识别猫眼。多个模式可以`加权`之后再作为下一个卷积层的多通道输入。

### 1X1卷积层

1x1卷积核不识别空间模式，只是用来融合通道。即上面提到的`加权`操作

# 池化层 Pooling

起因是我们需要一定程度的平移不变性，如卷积层在边缘检测中对图像边界太过敏感。

## 二维最大池化层

如2x2 max pooling， 即在这四个格子中找最大的值输出。与卷积相比，没有了做积的概念。

另外还有平均池化层

```python
pool2d = nn.MaxPool2d(n)
# pytorch默认步幅和窗口大小是一样的，也就是池化的窗口是不会重叠的
# 当然，也可以手动指定
pool2d = nn.MaxPool2d((2,3), padding=(1,1), stride=(2,3))
```

# LeNet

主要提出是用于手写数字识别

结构图

![image-20211020164650170](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20211020164650170.png)

pytorch实现

```python
net = torch.nn.Sequential(
	nn.Conv2d(1,6,kernel_size=5,padding=2),nn.Sigmoid(),
    nn.AvgPool2d(2,stride=2),
    nn.Conv2d(6,16,kernel_size=5),nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2,stride=2),
    nn.Flatten(),# 保持第一维，后面的维度全部拉成一个向量，为了输入后续的MLP
    nn.Linear(16*5*5,120),nn.Sigmoid(),
    nn.Linear(120,84),nn.Sigmoid(),
    nn.Linear(84,10)
)

for layer in net:
    X = layer(X)
```

# AlexNet

1980 - 1990 神经网络

2000 - 2010 核方法

2010 - 2020 神经网络

一般神经网络兴起的时间段代表计算能力足够支撑当时的数据量。

相比LeNet，给了人们新的计算机视觉的方法论，量变可以引起质变。

构建了端到端的模型，原始的就是一个图像的pixel，一句话的字符串等等，不需要进行人工的特征提取，输出就是我们要预测的分类等等。

相比lenet，Alexnet更大更深，有大约10倍的参数个数，260倍的计算复杂度，新加入了丢弃法，ReLU，maxpooling以及数据增强。

AlexNet赢下2012ImageNet竞赛后，引发了新的一轮神经网络热潮。

# VGG

相比AlexNet更深更大，更多的FC，更多的卷积层，将卷积层组合成块。

# NiN(Network in Network)

一个NiN块，是一个卷积层+两个全连接层。

# GoogLeNet

Inception块，综合前面的模型，不同大小的卷积，maxpooling都要有。

![image-20220102214447470](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220102214447470.png)

堆叠了有9个inception块

对比AlexNet，可以看到都是尽可能快地增大通道数，降低图像宽高

# Batch Norm

思想不新，但层是比较新的

一般来说，越靠近input，梯度会越来越小，而越靠近loss function，梯度会比较大。所以后层会训练地比较快，而前层会训练地比较慢，而前层训练后，后层又得重新训练了。

批量归一化

---

1. 固定小批量里面的均值和方差，使得前后层梯度都比较稳定。

   <img src="https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220102222632599.png" alt="image-20220102222632599" style="zoom:50%;" />

   1. 可学习的参数为$$\gamma$$以及$$\beta$$，相当于缩放和偏移
   2. 一般作用在全连接层和卷积层输出上，激活函数前
   3. 对全连接层，作用在特征维度
   4. 对卷积层，作用在通道维

一般可以加速收敛，但一般不改变模型精度

# ResNet

保证更深的层的效果不会变差，残差块使得很深的网络更加容易训练，因为复杂的模型块都包含简单模型。

$$f(x) = x + g(x)$$

相当于x是原始的输入，g(x)是当前层，f(x)是当前输出，当前的输出由原始输入与x经过一个模型得到的g(x)组合得到输出。ResNet的解释是这样残差连接可以加快梯度的下降。

resnet是直接矩阵对应元素**相加**，而前面的googlenet是concat。 

![image-20220211220119061](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220211220119061.png)

架构很类似VGG或googleNet，多个块。最前面的可能是stride为1的使宽高减半的块，后面的都是使宽高不变的块。

梯度消失问题：

![image-20220113205112527](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220113205112527.png)

ResNet是如何解决梯度消失的：相当于大数加小数，让梯度不至于过小。

![image-20220113205153493](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220113205153493.png)

# CPU GPU TPU

| \        | CPU           | GPU           |
| -------- | ------------- | ------------- |
| core     | 6/64          | 2K/4K         |
| TFLOPS   | 0.2/1         | 10/100        |
| 内存大小 | 32GB/1TB      | 16GB/32GB     |
| 内存带宽 | 30GBs/100GB/s | 400GB/s/1TB/s |
| 控制流   | 强            | 弱            |

CPU类似于几个博士生，而GPU类似于成千上万个小学生。

CPU可以处理通用计算。性能优化考虑数据读写效率和多线程

GPU使用更多的小核和更好的内存带宽，适合能大规模并行的计算任务

Google TPU

---

能媲美Nvidia GPU性能，在Google大量部署，专门用于深度学习，用于大矩阵乘法。

TPU灵活性较差，只能用于具体的任务，但便宜且效率高。

多GPU训练

---

每个GPU上的参数都是一样的，每次计算梯度需要先把每个GPU上的数据加和，再将梯度的更新回传给每个GPU，保证每个GPU上参数一致。（同步SGD）

分布式计算

---

与单机多卡其实没有很大的区别

尽量本地多通讯，少在机器之间走，类似spark hadoop了。

# 数据增广 data augmentation

在一个已有的数据集上，对数据进行不同的变换，使得有更多的多样性，以适应不同的使用场景。

每次的数据是**在线**生成的。训练时，先读取一份原始数据，然后将这部分数据随机地增强，再送入模型训练。

常用处理图片的方式：翻转、裁切、颜色、增加噪点

可以帮助**缓解过拟合**

# 微调 迁移学习transfer learning

在大数据集上训练好的模型，拿过来再次训练精细目标。类似于在yolo可以识别person的基础上，去在新数据集上识别人的head。

<img src="https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220114173716081.png" alt="image-20220114173716081" style="zoom:50%;" />

模型除了最后的output layer外，其他层的结构和参数都初始化成和原模型相同。这样即使是构建的初始模型，很可能已经能有不错的表现。

但我们会使用更小的学习率以及使用更少的数据迭代。源数据集远复杂于目标数据，通常微调效果更好。

```python
pretrained_net = trochvision.models.resnet18(pretrained = True)
pretrained_net.fc = nn.Linear(pretrained_net.fc.in_features = number)
nn.init.xavier_uniform_(pretrained_net.fc.weig)
```

# 物体检测

目标检测与图片分类的区别在于可以在一张图中识别出多个物体，并找到他们的位置。

锚框

---

对boundingbox的位置的猜测

大致思路：提出多个被称为锚框的区域，预测每个锚框里是否含有关注的物体，如果是，预测从这个锚框到真实boundingbox的偏移。

用IoU-交并比表示两个框之间的相似度。$$Intersection / Union$$。

赋予锚框标号：将每个锚框要么标注成背景，要么关联上一个真实boundingbox

NMS（非极大值抑制）输出：合并相似的预测框，选中是非背景类的最大预测值，去掉所有其他和它IoU值大于$$\theta$$的框，迭代。

# R-CNN

* 使用启发式搜索算法来选择锚框
* 使用预训练模型来对每个锚框抽取特征
* 训练一个SVM来对类别分类
* 训练一个线性回归来预测边缘框偏移

引入RoI池化层，有点类似maxpooling，将每个锚框的区域分割为n\*m个小区域，每个小区域取一个最大值，输出的是一个n\*m的矩阵。

# YOLO

将图片均匀分成$$S\times S$$个锚框，每个锚框预测B个边缘框

# 语义分割

![image-20220206224057953](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220206224057953.png)

要对每一个像素做分类任务

# 转置卷积

通常卷积不会增大输入的高宽，但转置卷积则可以用来增大输入高宽。

![image-20220206224604778](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220206224604778.png)

# FCN 全连接卷积神经网络

用转置卷积层替换CNN最后的全连接层，从而实现每个像素的预测

![image-20220206234816390](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220206234816390.png)

最后的通道数K为类别数

# 序列模型

![image-20220207212104149](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220207212104149.png)

自回归：auto regression

方案A：马尔科夫假设，假设当前数据只跟有限个过去数据点相关

方案B：潜变量模型，引入潜变量$$h_t$$来表示过去的所有信息，根据潜变量来对当前值进行预测

# 文本预处理

token：可以是word，可以是character

vocabulary：词汇表，将每一个token映射到从0开始的索引上

# RNN

## 梯度剪裁

能有效预防梯度爆炸，如果梯度长度超过$$\theta$$，就把长度投影回$$\theta$$
$$
\mathbf{g} \leftarrow \min \left(1, \frac{\theta}{\|\mathbf{g}\|}\right) \mathbf{g}
$$

# 门控循环单元GRU

两个门

![image-20220211205125668](https://raw.githubusercontent.com/Jia-py/blog_picture/master/img/image-20220211205125668.png)

$$\odot$$表示对应维度相乘点积

